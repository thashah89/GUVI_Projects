{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.redbus.in/bus-tickets/rajahmundry-to-vijayawada?fromCityId=71757&toCityId=134&fromCityName=Rajahmundry&toCityName=Vijayawada&busType=Any&srcCountry=IND&destCountry=null&onward=02-Dec-2024');\n",
    "time.sleep(10)\n",
    "\n",
    "def is_at_end_of_page(driver):\n",
    "    \"Check if the webpage is scrolled to the bottom.\"\n",
    "    scroll_position = driver.execute_script(\"return window.scrollY;\")\n",
    "    page_height = driver.execute_script(\"return document.documentElement.scrollHeight;\")\n",
    "    viewport_height = driver.execute_script(\"return window.innerHeight;\")\n",
    "    return scroll_position + viewport_height >= page_height\n",
    "\n",
    "def scroll_page(driver):\n",
    "    \"Scrolls the page to the bottom.\"\n",
    "    while not is_at_end_of_page(driver):\n",
    "        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    \n",
    "scroll_page(driver)\n",
    "\n",
    "bus_elements = driver.find_elements(By.XPATH, \"//*[@class='row-sec clearfix']\")\n",
    "bus_data = []\n",
    "for bus in bus_elements:\n",
    "    try:\n",
    "        # Try to find the star rating element\n",
    "        star_rating_element = bus.find_element(By.XPATH, \".//*[@class='column-six p-right-10 w-10 fl']\")\n",
    "        star_rating_text = star_rating_element.text.strip()\n",
    "        if star_rating_text:\n",
    "            star_rating = star_rating_text.split()[0].replace('New', '0')  # Process rating\n",
    "        else:\n",
    "            star_rating = 0\n",
    "    except Exception as e:\n",
    "        print(f\"Star rating not found or invalid: {e}\")\n",
    "\n",
    "    # Append all data to the list\n",
    "    bus_data.append({\n",
    "        \"bus_name\": bus.find_element(By.XPATH, \".//*[@class='travels lh-24 f-bold d-color']\").text,\n",
    "        \"bus_type\": bus.find_element(By.XPATH, \".//*[@class='bus-type f-12 m-top-16 l-color evBus']\").text,\n",
    "        \"departing_time\": bus.find_element(By.XPATH, \".//*[@class='dp-time f-19 d-color f-bold']\").text,\n",
    "        \"duration\": bus.find_element(By.XPATH, \".//*[@class='dur l-color lh-24']\").text,\n",
    "        \"reaching_time\": bus.find_element(By.XPATH, \".//*[@class='bp-time f-19 d-color disp-Inline']\").text,\n",
    "        \"star_rating\": star_rating,\n",
    "        \"price\": bus.find_element(By.XPATH, \".//div[contains(@class, 'fare d-block')]//span\").text,\n",
    "        \"seat_availability\": bus.find_element(By.XPATH, \".//*[contains(@class, 'column-eight w-15 fl')]/div[1]\").text.split(' ')[0],\n",
    "    })\n",
    "\n",
    "# Export the data to Excel\n",
    "df = pd.DataFrame(bus_data)\n",
    "df.to_excel('new.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Kerala...\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "\n",
    "# Database Connection and Setup\n",
    "def setup_database():\n",
    "    try:\n",
    "        mydb = pymysql.connect(host='127.0.0.1', user='root', password='ShahulSqL2024')\n",
    "        cursor = mydb.cursor()\n",
    "        cursor.execute(\"CREATE DATABASE IF NOT EXISTS redbus\")\n",
    "        cursor.execute(\"USE redbus\")\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS bus_routes\")\n",
    "        cursor.execute(\"CREATE TABLE IF NOT EXISTS bus_routes (\"\n",
    "                       \"id INT AUTO_INCREMENT PRIMARY KEY, \"\n",
    "                       \"state VARCHAR(50), \"\n",
    "                       \"bus_route_name TEXT, \"\n",
    "                       \"bus_route_link TEXT, \"\n",
    "                       \"bus_name TEXT, \"\n",
    "                       \"bus_type TEXT, \"\n",
    "                       \"departing_time TIME, \"\n",
    "                       \"duration TEXT, \"\n",
    "                       \"reaching_time TIME, \"\n",
    "                       \"star_rating FLOAT, \"\n",
    "                       \"price DECIMAL(10, 2), \"\n",
    "                       \"seat_availability INT)\")\n",
    "        return create_engine(\"mysql+pymysql://root:ShahulSqL2024@127.0.0.1/redbus\")\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"Database Error: {e}\")\n",
    "        exit()\n",
    "\n",
    "# Web Scraping Functions\n",
    "def is_at_end_of_page(driver):\n",
    "    \"Check if the webpage is scrolled to the bottom.\"\n",
    "    scroll_position = driver.execute_script(\"return window.scrollY;\")\n",
    "    page_height = driver.execute_script(\"return document.documentElement.scrollHeight;\")\n",
    "    viewport_height = driver.execute_script(\"return window.innerHeight;\")\n",
    "    return scroll_position + viewport_height >= page_height\n",
    "\n",
    "def scroll_page(driver):\n",
    "    \"Scrolls the page to the bottom.\"\n",
    "    while not is_at_end_of_page(driver):\n",
    "        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "def extract_route_data(driver, state, route_name, route_link):\n",
    "    \"Extracts data for a single route.\"\n",
    "    driver.get(route_link)\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        # Handle cases where buses are not found\n",
    "        if len(driver.find_elements(By.XPATH, \"//h3[text()='Oops! No buses found.']\")) > 0:\n",
    "            driver.find_element(By.XPATH, \"//*[@id='fixer']/div/div/div[1]/span[@class='next']\").click()\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Expand all bus listings\n",
    "        expand_buttons = driver.find_elements(By.XPATH, \"//*[@class='button']\")\n",
    "        for btn in reversed(expand_buttons):\n",
    "            btn.click()\n",
    "            time.sleep(3)\n",
    "\n",
    "        scroll_page(driver)\n",
    "\n",
    "        # Extract bus data\n",
    "        bus_elements = driver.find_elements(By.XPATH, \"//*[@class='row-sec clearfix']\")\n",
    "        route_data = []\n",
    "        for bus in bus_elements:\n",
    "            \n",
    "            try:\n",
    "                # Try to find the star rating element\n",
    "                star_rating_element = bus.find_element(By.XPATH, \".//*[@class='column-six p-right-10 w-10 fl']\")\n",
    "                star_rating_text = star_rating_element.text.strip()\n",
    "                if star_rating_text:\n",
    "                    star_rating = star_rating_text.split()[0].replace('New', '0')  # Process rating\n",
    "                else:\n",
    "                    star_rating = 0\n",
    "            except Exception as e:\n",
    "                print(f\"Star rating not found or invalid: {e}\")\n",
    "\n",
    "            \n",
    "            route_data.append({\n",
    "                \"state\": state,\n",
    "                \"bus_route_name\": route_name,\n",
    "                \"bus_route_link\": route_link,\n",
    "                \"bus_name\": bus.find_element(By.XPATH, \".//*[@class='travels lh-24 f-bold d-color']\").text,\n",
    "                \"bus_type\": bus.find_element(By.XPATH, \".//*[@class='bus-type f-12 m-top-16 l-color evBus']\").text,\n",
    "                \"departing_time\": bus.find_element(By.XPATH, \".//*[@class='dp-time f-19 d-color f-bold']\").text,\n",
    "                \"duration\": bus.find_element(By.XPATH, \".//*[@class='dur l-color lh-24']\").text,\n",
    "                \"reaching_time\": bus.find_element(By.XPATH, \".//*[@class='bp-time f-19 d-color disp-Inline']\").text,\n",
    "                \"star_rating\": star_rating,\n",
    "                \"price\": bus.find_element(By.XPATH, \".//div[contains(@class, 'fare d-block')]//span\").text,\n",
    "                \"seat_availability\": bus.find_element(By.XPATH, \".//*[contains(@class, 'column-eight w-15 fl')]/div[1]\").text.split(' ')[0]\n",
    "            })\n",
    "        return route_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data for {route_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_state_data(driver, state, state_url):\n",
    "    \"Scrapes all routes for a given state.\"\n",
    "    actions = ActionChains(driver)\n",
    "    driver.get(state_url)\n",
    "    route_name, route_link, route_data = [], [], []\n",
    "    \n",
    "    # identifying the number of pages found in each web page\n",
    "    no_of_pages = len(driver.find_elements(By.CLASS_NAME, 'DC_117_pageTabs '))\n",
    "\n",
    "    # looping through the pages\n",
    "    for n in range(1,no_of_pages+1):\n",
    "        actions.move_to_element(driver.find_element(By.XPATH, \"//*[@id='root']/div/div[4]/div[12]/div[text()='\" + str(n) + \"']\")).click()\n",
    "        actions.perform()\n",
    "        routes = driver.find_elements(By.XPATH, \"//a[@class='route']\")\n",
    "        \n",
    "        # looping through the selenium object to extract data into the list\n",
    "        for route in routes:\n",
    "            route_name.append(route.text)\n",
    "            route_link.append(route.get_attribute('href'))\n",
    "    \n",
    "    for r_name, r_link in zip(route_name,route_link):\n",
    "        route_data.extend(extract_route_data(driver, state, r_name, r_link))\n",
    "    return route_data\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    engine = setup_database()\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.maximize_window()\n",
    "\n",
    "    transport_states = ['Kerala']\n",
    "    transport_urls = [\n",
    "        'https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile',\n",
    "    ]\n",
    "\n",
    "    for state, url in zip(transport_states, transport_urls):\n",
    "        print(f\"Scraping data for {state}...\")\n",
    "        state_data = scrape_state_data(driver, state, url)\n",
    "        if state_data:\n",
    "            df = pd.DataFrame(state_data)\n",
    "            df.to_sql('bus_routes',engine , if_exists='append', index=False)\n",
    "            df.to_csv(f\"{state}.csv\", index=False)\n",
    "            print(f\"{state} data scraped and saved successfully.\")\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"Scraping completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.redbus.in/bus-tickets/rajahmundry-to-vijayawada?fromCityId=71757&toCityId=134&fromCityName=Rajahmundry&toCityName=Vijayawada&busType=Any&srcCountry=IND&destCountry=null&onward=02-Dec-2024');\n",
    "time.sleep(10)\n",
    "\n",
    "def is_at_end_of_page(driver):\n",
    "    \"Check if the webpage is scrolled to the bottom.\"\n",
    "    scroll_position = driver.execute_script(\"return window.scrollY;\")\n",
    "    page_height = driver.execute_script(\"return document.documentElement.scrollHeight;\")\n",
    "    viewport_height = driver.execute_script(\"return window.innerHeight;\")\n",
    "    return scroll_position + viewport_height >= page_height\n",
    "\n",
    "def scroll_page(driver):\n",
    "    \"Scrolls the page to the bottom.\"\n",
    "    while not is_at_end_of_page(driver):\n",
    "        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    \n",
    "scroll_page(driver)\n",
    "\n",
    "bus_elements = driver.find_elements(By.XPATH, \"//*[@class='row-sec clearfix']\")\n",
    "bus_data = []\n",
    "for bus in bus_elements:\n",
    "    bus_data.append({\n",
    "                \"bus_name\": bus.find_element(By.XPATH, \".//*[@class='travels lh-24 f-bold d-color']\").text,\n",
    "                \"bus_type\": bus.find_element(By.XPATH, \".//*[@class='bus-type f-12 m-top-16 l-color evBus']\").text,\n",
    "                \"departing_time\": bus.find_element(By.XPATH, \".//*[@class='dp-time f-19 d-color f-bold']\").text,\n",
    "                \"duration\": bus.find_element(By.XPATH, \".//*[@class='dur l-color lh-24']\").text,\n",
    "                \"reaching_time\": bus.find_element(By.XPATH, \".//*[@class='bp-time f-19 d-color disp-Inline']\").text,\n",
    "                \"star_rating\": bus.find_element(By.XPATH, \".//*[@class='column-six p-right-10 w-10 fl']\").text if bus.find_element(By.XPATH, \".//*[@class='column-six p-right-10 w-10 fl']\").text == None else bus.find_element(By.XPATH, \".//*[@class='column-six p-right-10 w-10 fl']\").text.split()[0].replace('new','0'),\n",
    "                \"price\": bus.find_element(By.XPATH, \".//div[contains(@class, 'fare d-block')]//span\").text,\n",
    "                \"seat_availability\": bus.find_element(By.XPATH, \".//*[contains(@class, 'column-eight w-15 fl')]/div[1]\").text.split(' ')[0]\n",
    "            })\n",
    "    df = pd.DataFrame(bus_data)\n",
    "    df.to_excel('new.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
